{
  "models": {
    "gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4o": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4o-audio-preview": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_audio_token": 0.0001,
      "output_cost_per_token": 0.000010,
      "output_cost_per_audio_token": 0.0002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true
    },
    "gpt-4o-audio-preview-2024-10-01": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_audio_token": 0.0001,
      "output_cost_per_token": 0.000010,
      "output_cost_per_audio_token": 0.0002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true
    },
    "gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.00000060,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4o-mini-2024-07-18": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.00000060,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o1-preview": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "chatgpt-4o-latest": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4o-2024-05-13": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.000010,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4-turbo-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4-0314": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-4-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-4-32k-0314": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-4-32k-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4-turbo-2024-04-09": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4-1106-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4-0125-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-4-vision-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-4-1106-vision-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo": {
      "max_tokens": 4097,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-0301": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-0613": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-1106": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000010,
      "output_cost_per_token": 0.0000020,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-0125": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-16k": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "gpt-3.5-turbo-16k-0613": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true
    },
    "text-embedding-3-large": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 3072,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "text-embedding-3-small": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 0.00000002,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "text-embedding-ada-002": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "text-embedding-ada-002-v2": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "azure/o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/o1-preview": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/gpt-4o": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "output_cost_per_token": 0.000011,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    "azure/gpt-4o-2024-05-13": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.000010,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    "azure/global-standard/gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.00000060,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    "azure/gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/gpt-4o-mini-2024-07-18": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "azure/gpt-4-turbo-2024-04-09": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    "azure/gpt-4-0125-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-4-1106-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-4-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/gpt-4-32k-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    "azure/gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    "azure/gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-4-turbo-vision-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": true
    },
    "azure/gpt-35-turbo-16k-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/gpt-35-turbo-1106": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-35-turbo-0613": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-35-turbo-0301": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000002,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-35-turbo-0125": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    "azure/gpt-35-turbo-16k": {
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    "azure/gpt-35-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct-0914": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    "azure/mistral-large-latest": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/mistral-large-2402": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/command-r-plus": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/ada": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-ada-002": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-large": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-small": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.00000002,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/standard/1024-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.0000000381469,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1024-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000007629,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1024-x-1792/dall-e-3": {
      "input_cost_per_pixel": 0.00000004359,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1792-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000004359,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1024-x-1792/dall-e-3": {
      "input_cost_per_pixel": 0.00000006539,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1792-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000006539,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1024-x-1024/dall-e-2": {
      "input_cost_per_pixel": 0.0,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure_ai/jamba-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000007,
      "litellm_provider": "azure_ai",
      "mode": "chat"
    },
    "azure_ai/mistral-large": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure_ai/mistral-small": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat"
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.00000037,
      "litellm_provider": "azure_ai",
      "mode": "chat"
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.0000003,
      "output_cost_per_token": 0.00000061,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice"
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000268,
      "output_cost_per_token": 0.00000354,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice"
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000533,
      "output_cost_per_token": 0.000016,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice"
    },
    "azure_ai/cohere-rerank-v3-multilingual": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_query_tokens": 2048,
      "input_cost_per_token": 0.0,
      "input_cost_per_query": 0.002,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "rerank"
    },
    "azure_ai/cohere-rerank-v3-english": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_query_tokens": 2048,
      "input_cost_per_token": 0.0,
      "input_cost_per_query": 0.002,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "rerank"
    },
    "azure_ai/Cohere-embed-v3-english": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "output_vector_size": 1024,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "embedding",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice"
    },
    "azure_ai/Cohere-embed-v3-multilingual": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "output_vector_size": 1024,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "embedding",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice"
    }
  }
}