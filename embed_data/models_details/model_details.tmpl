{
  "models": {
    "gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4o": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "input_cost_per_token_batches": 0.00000125,
      "output_cost_per_token_batches": 0.000005,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "output_cost_per_token_batches": 3e-7,
      "cache_read_input_token_cost": 7.5e-8,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4.1": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-6,
      "output_cost_per_token": 8e-6,
      "input_cost_per_token_batches": 1e-6,
      "output_cost_per_token_batches": 4e-6,
      "cache_read_input_token_cost": 0.5e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 30e-3,
        "search_context_size_medium": 35e-3,
        "search_context_size_high": 50e-3
      }
    },
    "gpt-4.1-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-6,
      "output_cost_per_token": 8e-6,
      "input_cost_per_token_batches": 1e-6,
      "output_cost_per_token_batches": 4e-6,
      "cache_read_input_token_cost": 0.5e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 30e-3,
        "search_context_size_medium": 35e-3,
        "search_context_size_high": 50e-3
      }
    },
    "gpt-4.1-mini": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.4e-6,
      "output_cost_per_token": 1.6e-6,
      "input_cost_per_token_batches": 0.2e-6,
      "output_cost_per_token_batches": 0.8e-6,
      "cache_read_input_token_cost": 0.1e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 25e-3,
        "search_context_size_medium": 27.5e-3,
        "search_context_size_high": 30e-3
      }
    },
    "gpt-4.1-mini-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.4e-6,
      "output_cost_per_token": 1.6e-6,
      "input_cost_per_token_batches": 0.2e-6,
      "output_cost_per_token_batches": 0.8e-6,
      "cache_read_input_token_cost": 0.1e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 25e-3,
        "search_context_size_medium": 27.5e-3,
        "search_context_size_high": 30e-3
      }
    },
    "gpt-4.1-nano": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.1e-6,
      "output_cost_per_token": 0.4e-6,
      "input_cost_per_token_batches": 0.05e-6,
      "output_cost_per_token_batches": 0.2e-6,
      "cache_read_input_token_cost": 0.025e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true
    },
    "gpt-4.1-nano-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.1e-6,
      "output_cost_per_token": 0.4e-6,
      "input_cost_per_token_batches": 0.05e-6,
      "output_cost_per_token_batches": 0.2e-6,
      "cache_read_input_token_cost": 0.025e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true
    },
    "o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 5.5e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o3-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 5.5e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "o3": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1e-5,
      "output_cost_per_token": 4e-5,
      "cache_read_input_token_cost": 2.5e-6,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "o4-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1.1e-6,
      "output_cost_per_token": 4.4e-6,
      "cache_read_input_token_cost": 2.75e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "o4-mini-2025-04-16": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1.1e-6,
      "output_cost_per_token": 4.4e-6,
      "cache_read_input_token_cost": 2.75e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-3.5-turbo": {
      "max_tokens": 4097,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "claude-3-opus-20240229": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-03-01",
      "supports_tool_choice": true
    },
    "claude-opus-4-20250514": {
      "max_tokens": 32000,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 15e-6,
      "output_cost_per_token": 75e-6,
      "search_context_cost_per_query": {
        "search_context_size_low": 1e-2,
        "search_context_size_medium": 1e-2,
        "search_context_size_high": 1e-2
      },
      "cache_creation_input_token_cost": 18.75e-6,
      "cache_read_input_token_cost": 1.5e-6,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_computer_use": true
    },
    "claude-sonnet-4-20250514": {
      "max_tokens": 64000,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 3e-6,
      "output_cost_per_token": 15e-6,
      "search_context_cost_per_query": {
        "search_context_size_low": 1e-2,
        "search_context_size_medium": 1e-2,
        "search_context_size_high": 1e-2
      },
      "cache_creation_input_token_cost": 3.75e-6,
      "cache_read_input_token_cost": 0.3e-6,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_computer_use": true
    },
    "claude-3-7-sonnet-latest": {
      "supports_computer_use": true,
      "max_tokens": 128000,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_low": 1e-2,
        "search_context_size_medium": 1e-2,
        "search_context_size_high": 1e-2
      },
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 0.0000003,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-06-01",
      "supports_tool_choice": true,
      "supports_reasoning": true
    },
    "claude-3-7-sonnet-20250219": {
      "supports_computer_use": true,
      "max_tokens": 128000,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 0.0000003,
      "search_context_cost_per_query": {
        "search_context_size_low": 1e-2,
        "search_context_size_medium": 1e-2,
        "search_context_size_high": 1e-2
      },
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2026-02-01",
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_web_search": true
    },
    "claude-3-5-haiku-20241022": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "tool_use_system_prompt_tokens": 264,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-10-01",
      "supports_tool_choice": true
    },
    "claude-3-5-sonnet-20240620": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-06-01",
      "supports_tool_choice": true
    },
    "claude-3-5-sonnet-20241022": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-10-01",
      "supports_tool_choice": true
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-r1": {
      "max_tokens": 8192,
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000055,
      "input_cost_per_token_cache_hit": 0.00000014,
      "output_cost_per_token": 0.00000219,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true
    },
    "openrouter/deepseek/deepseek-chat": {
      "max_tokens": 8192,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000014,
      "output_cost_per_token": 0.00000028,
      "litellm_provider": "openrouter",
      "supports_prompt_caching": true,
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-coder": {
      "max_tokens": 8192,
      "max_input_tokens": 66000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000014,
      "output_cost_per_token": 0.00000028,
      "litellm_provider": "openrouter",
      "supports_prompt_caching": true,
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/google/gemini-pro-1.5": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.0000075,
      "input_cost_per_image": 0.00265,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_tool_choice": true
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
      "max_tokens": 65536,
      "input_cost_per_token": 0.00000065,
      "output_cost_per_token": 0.00000065,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-haiku": {
      "max_tokens": 200000,
      "input_cost_per_token": 0.00000025,
      "output_cost_per_token": 0.00000125,
      "input_cost_per_image": 0.0004,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku": {
      "max_tokens": 200000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000025,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 264,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku-20241022": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "tool_use_system_prompt_tokens": 264,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "supports_computer_use": true,
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
      "supports_computer_use": true,
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "supports_computer_use": true,
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "input_cost_per_image": 0.0048,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.7-sonnet:beta": {
      "supports_computer_use": true,
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "input_cost_per_image": 0.0048,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-sonnet": {
      "max_tokens": 200000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "input_cost_per_image": 0.0048,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-large": {
      "max_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "mistralai/mistral-small-3.1-24b-instruct": {
      "max_tokens": 32000,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/google/gemini-pro-vision": {
      "max_tokens": 45875,
      "input_cost_per_token": 0.000000125,
      "output_cost_per_token": 0.000000375,
      "input_cost_per_image": 0.0025,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.0,
      "output_cost_per_token": 0.0,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-8b-instruct:extended": {
      "max_tokens": 16384,
      "input_cost_per_token": 0.000000225,
      "output_cost_per_token": 0.00000225,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.0000009,
      "output_cost_per_token": 0.0000009,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.00000059,
      "output_cost_per_token": 0.00000079,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/o1-preview": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/o3-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/o3-mini-high": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4o": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.000010,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4-vision-preview": {
      "max_tokens": 130000,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "input_cost_per_image": 0.01445,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "max_tokens": 4095,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "max_tokens": 16383,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-instant-v1": {
      "max_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000163,
      "output_cost_per_token": 0.00000551,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-2": {
      "max_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00001102,
      "output_cost_per_token": 0.00003268,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-opus": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "supports_tool_choice": true
    },
    "openrouter/google/palm-2-chat-bison": {
      "max_tokens": 25804,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/google/palm-2-codechat-bison": {
      "max_tokens": 20070,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
      "max_tokens": 4096,
      "input_cost_per_token": 0.0000002,
      "output_cost_per_token": 0.0000002,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
      "max_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-7b-instruct": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.00000013,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.0,
      "output_cost_per_token": 0.0,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "max_tokens": 33792,
      "max_input_tokens": 33792,
      "max_output_tokens": 33792,
      "input_cost_per_token": 0.00000018,
      "output_cost_per_token": 0.00000018,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000002,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000045,
      "output_cost_per_token": 0.0000007,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "mistral.mistral-large-2402-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "mistral.mistral-large-2407-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "mistral.mistral-small-2402-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000045,
      "output_cost_per_token": 0.0000007,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000045,
      "output_cost_per_token": 0.0000007,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000059,
      "output_cost_per_token": 0.00000091,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000002,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000002,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000002,
      "output_cost_per_token": 0.00000026,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000104,
      "output_cost_per_token": 0.0000312,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "gemini-pro": {
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supports_tool_choice": true
    },
    "gemini-1.0-pro": {
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
      "supports_tool_choice": true
    },
    "gemini-1.0-pro-001": {
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "deprecation_date": "2025-04-09",
      "supports_tool_choice": true
    },
    "gemini-1.0-ultra": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.0-ultra-001": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.0-pro-002": {
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 0.0000005,
      "input_cost_per_character": 0.000000125,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 0.000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "deprecation_date": "2025-04-09",
      "supports_tool_choice": true
    },
    "gemini-1.5-pro": {
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.000005,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_vision": true,
      "supports_pdf_input": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-002": {
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.000005,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
      "deprecation_date": "2025-09-24"
    },
    "gemini-1.5-pro-001": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.000005,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "deprecation_date": "2025-05-24"
    },
    "gemini-1.5-pro-preview-0514": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.000000078125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.00000015625,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.0000003125,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.000000625,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-preview-0215": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.000000078125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.00000015625,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.0000003125,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.000000625,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-preview-0409": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_token": 0.000000078125,
      "input_cost_per_character": 0.0000003125,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_token_above_128k_tokens": 0.00000015625,
      "input_cost_per_character_above_128k_tokens": 0.000000625,
      "output_cost_per_token": 0.0000003125,
      "output_cost_per_character": 0.00000125,
      "output_cost_per_token_above_128k_tokens": 0.000000625,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-flash": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.00002,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_token": 0.000000075,
      "input_cost_per_character": 0.00000001875,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 0.00000025,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "output_cost_per_token": 0.0000003,
      "output_cost_per_character": 0.000000075,
      "output_cost_per_token_above_128k_tokens": 0.0000006,
      "output_cost_per_character_above_128k_tokens": 0.00000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.5-flash-exp-0827": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.00002,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_token": 0.000000004688,
      "input_cost_per_character": 0.00000001875,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 0.00000025,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "output_cost_per_token": 0.0000000046875,
      "output_cost_per_character": 0.00000001875,
      "output_cost_per_token_above_128k_tokens": 0.000000009375,
      "output_cost_per_character_above_128k_tokens": 0.0000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.5-flash-002": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.00002,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_token": 0.000000075,
      "input_cost_per_character": 0.00000001875,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 0.00000025,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "output_cost_per_token": 0.0000003,
      "output_cost_per_character": 0.000000075,
      "output_cost_per_token_above_128k_tokens": 0.0000006,
      "output_cost_per_character_above_128k_tokens": 0.00000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
      "deprecation_date": "2025-09-24",
      "supports_tool_choice": true
    },
    "gemini-1.5-flash-001": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.00002,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_token": 0.000000075,
      "input_cost_per_character": 0.00000001875,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 0.00000025,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "output_cost_per_token": 0.0000003,
      "output_cost_per_character": 0.000000075,
      "output_cost_per_token_above_128k_tokens": 0.0000006,
      "output_cost_per_character_above_128k_tokens": 0.00000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "deprecation_date": "2025-05-24",
      "supports_tool_choice": true
    },
    "gemini-1.5-flash-preview-0514": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.00002,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_token": 0.000000075,
      "input_cost_per_character": 0.00000001875,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 0.00000025,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "output_cost_per_token": 0.0000000046875,
      "output_cost_per_character": 0.00000001875,
      "output_cost_per_token_above_128k_tokens": 0.000000009375,
      "output_cost_per_character_above_128k_tokens": 0.0000000375,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-pro-experimental": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "input_cost_per_character": 0,
      "output_cost_per_character": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_tool_choice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "gemini-flash-experimental": {
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "input_cost_per_character": 0,
      "output_cost_per_character": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_tool_choice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "gemini-pro-vision": {
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "input_cost_per_image": 0.0025,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.0-pro-vision": {
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "input_cost_per_image": 0.0025,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true
    },
    "gemini-1.0-pro-vision-001": {
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "input_cost_per_image": 0.0025,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "deprecation_date": "2025-04-09",
      "supports_tool_choice": true
    },
    "gemini-2.5-pro-exp-03-25": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_audio_input": true,
      "supports_video_input": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini-2.0-pro-exp-02-05": {
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_audio_input": true,
      "supports_video_input": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini-2.0-flash-exp": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0.00000015,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0.0000006,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supports_tool_choice": true
    },
    "gemini-2.0-flash-001": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000006,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "deprecation_date": "2026-02-05"
    },
    "gemini-2.0-flash-thinking-exp": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
      "max_tokens": 65536,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_response_schema": false,
      "supports_audio_output": false,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini/gemini-2.5-pro-exp-03-25": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_token": 0.0,
      "input_cost_per_token_above_200k_tokens": 0.0,
      "output_cost_per_token": 0.0,
      "output_cost_per_token_above_200k_tokens": 0.0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 5,
      "tpm": 250000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_audio_input": true,
      "supports_video_input": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/gemini-2.5-flash-preview-tts": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 1e-6,
      "input_cost_per_token": 0.15e-6,
      "output_cost_per_token": 0.6e-6,
      "output_cost_per_reasoning_token": 3.5e-6,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10,
      "tpm": 250000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 1e-6,
      "input_cost_per_token": 0.15e-6,
      "output_cost_per_token": 0.6e-6,
      "output_cost_per_reasoning_token": 3.5e-6,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10,
      "tpm": 250000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 1e-6,
      "input_cost_per_token": 0.15e-6,
      "output_cost_per_token": 0.6e-6,
      "output_cost_per_reasoning_token": 3.5e-6,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10,
      "tpm": 250000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini-2.5-flash-preview-05-20": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 1e-6,
      "input_cost_per_token": 0.15e-6,
      "output_cost_per_token": 0.6e-6,
      "output_cost_per_reasoning_token": 3.5e-6,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini-2.5-flash-preview-04-17": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 1e-6,
      "input_cost_per_token": 0.15e-6,
      "output_cost_per_token": 0.6e-6,
      "output_cost_per_reasoning_token": 3.5e-6,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini-2.0-flash": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_audio_input": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_tool_choice": true,
      "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini-2.0-flash-lite": {
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 50,
      "input_cost_per_audio_token": 0.000000075,
      "input_cost_per_token": 0.000000075,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini-2.0-flash-lite-001": {
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 50,
      "input_cost_per_audio_token": 0.000000075,
      "input_cost_per_token": 0.000000075,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true,
      "deprecation_date": "2026-02-25"
    },
    "gemini-2.5-pro-preview-05-06": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.00000125,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini-2.5-pro-preview-03-25": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.00000125,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview"
    },
    "gemini-2.0-flash-preview-image-generation": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_audio_input": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_tool_choice": true,
      "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini-2.5-pro-preview-tts": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview"
    },
    "gemini/gemini-2.0-pro-exp-02-05": {
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 2,
      "tpm": 1000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_audio_input": true,
      "supports_video_input": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/gemini-2.0-flash-preview-image-generation": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_audio_input": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_tool_choice": true,
      "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.0-flash": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_audio_input": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_tool_choice": true,
      "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.0-flash-lite": {
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 50,
      "input_cost_per_audio_token": 0.000000075,
      "input_cost_per_token": 0.000000075,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "gemini",
      "mode": "chat",
      "tpm": 4000000,
      "rpm": 4000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-001": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0000004,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.5-pro-preview-tts": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview"
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview"
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
      "max_tokens": 65535,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.0000007,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 10000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview"
    },
    "gemini/gemini-2.0-flash-exp": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "tpm": 4000000,
      "rpm": 10,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_audio_token": 0.000000075,
      "input_cost_per_token": 0.000000075,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "gemini",
      "mode": "chat",
      "rpm": 60000,
      "tpm": 10000000,
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "supports_tool_choice": true,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "tpm": 4000000,
      "rpm": 10,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-thinking-exp-01-21": {
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": true,
      "tpm": 4000000,
      "rpm": 10,
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supports_tool_choice": true
    },
    "gemini/gemma-3-27b-it": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "source": "https://aistudio.google.com",
      "supports_tool_choice": true
    },
    "gemini/learnlm-1.5-pro-experimental": {
      "max_tokens": 8192,
      "max_input_tokens": 32767,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_token": 0,
      "input_cost_per_character": 0,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "output_cost_per_token": 0,
      "output_cost_per_character": 0,
      "output_cost_per_token_above_128k_tokens": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_response_schema": true,
      "supports_audio_output": false,
      "source": "https://aistudio.google.com",
      "supports_tool_choice": true
    },
    "xai/grok-beta": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "xai/grok-2-vision-1212": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_image": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "xai/grok-2-vision-latest": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_image": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "xai/grok-2-vision": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_image": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "xai/grok-3": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-beta": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-fast-beta": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000025,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-fast-latest": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000025,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-beta": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.0000003,
      "output_cost_per_token": 0.0000005,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-fast-beta": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.0000006,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-fast-latest": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.0000006,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": false,
      "source": "https://x.ai/api#pricing"
    },
    "xai/grok-vision-beta": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000005,
      "input_cost_per_image": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "xai/grok-2-1212": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "xai/grok-2": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "xai/grok-2-latest": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "xai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "deepseek/deepseek-reasoner": {
      "max_tokens": 8192,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000055,
      "input_cost_per_token_cache_hit": 0.00000014,
      "output_cost_per_token": 0.00000219,
      "litellm_provider": "deepseek",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_prompt_caching": true
    },
    "deepseek/deepseek-chat": {
      "max_tokens": 8192,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000027,
      "input_cost_per_token_cache_hit": 0.00000007,
      "cache_read_input_token_cost": 0.00000007,
      "cache_creation_input_token_cost": 0.0,
      "output_cost_per_token": 0.0000011,
      "litellm_provider": "deepseek",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true
    },
    "azure/gpt-4o-mini-tts": {
      "mode": "audio_speech",
      "input_cost_per_token": 2.5e-6,
      "output_cost_per_token": 10e-6,
      "output_cost_per_audio_token": 12e-6,
      "output_cost_per_second": 0.00025,
      "litellm_provider": "azure",
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "supported_endpoints": [
        "/v1/audio/speech"
      ]
    },
    "azure/computer-use-preview": {
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 3e-6,
      "output_cost_per_token": 12e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_reasoning": true
    },
    "azure/gpt-4o-audio-preview-2024-12-17": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "output_cost_per_token": 0.00001,
      "output_cost_per_audio_token": 0.00008,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": false,
      "supports_vision": false,
      "supports_prompt_caching": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_reasoning": false
    },
    "azure/gpt-4o-mini-audio-preview-2024-12-17": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "output_cost_per_token": 0.00001,
      "output_cost_per_audio_token": 0.00008,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": false,
      "supports_vision": false,
      "supports_prompt_caching": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_reasoning": false
    },
    "azure/gpt-4.1": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-6,
      "output_cost_per_token": 8e-6,
      "input_cost_per_token_batches": 1e-6,
      "output_cost_per_token_batches": 4e-6,
      "cache_read_input_token_cost": 0.5e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 30e-3,
        "search_context_size_medium": 35e-3,
        "search_context_size_high": 50e-3
      }
    },
    "azure/gpt-4.1-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-6,
      "output_cost_per_token": 8e-6,
      "input_cost_per_token_batches": 1e-6,
      "output_cost_per_token_batches": 4e-6,
      "cache_read_input_token_cost": 0.5e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 30e-3,
        "search_context_size_medium": 35e-3,
        "search_context_size_high": 50e-3
      }
    },
    "azure/gpt-4.1-mini": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.4e-6,
      "output_cost_per_token": 1.6e-6,
      "input_cost_per_token_batches": 0.2e-6,
      "output_cost_per_token_batches": 0.8e-6,
      "cache_read_input_token_cost": 0.1e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 25e-3,
        "search_context_size_medium": 27.5e-3,
        "search_context_size_high": 30e-3
      }
    },
    "azure/gpt-4.1-mini-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.4e-6,
      "output_cost_per_token": 1.6e-6,
      "input_cost_per_token_batches": 0.2e-6,
      "output_cost_per_token_batches": 0.8e-6,
      "cache_read_input_token_cost": 0.1e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_web_search": true,
      "search_context_cost_per_query": {
        "search_context_size_low": 25e-3,
        "search_context_size_medium": 27.5e-3,
        "search_context_size_high": 30e-3
      }
    },
    "azure/gpt-4.1-nano": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.1e-6,
      "output_cost_per_token": 0.4e-6,
      "input_cost_per_token_batches": 0.05e-6,
      "output_cost_per_token_batches": 0.2e-6,
      "cache_read_input_token_cost": 0.025e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true
    },
    "azure/gpt-4.1-nano-2025-04-14": {
      "max_tokens": 32768,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.1e-6,
      "output_cost_per_token": 0.4e-6,
      "input_cost_per_token_batches": 0.05e-6,
      "output_cost_per_token_batches": 0.2e-6,
      "cache_read_input_token_cost": 0.025e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true
    },
    "azure/o3": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1e-5,
      "output_cost_per_token": 4e-5,
      "cache_read_input_token_cost": 2.5e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "azure/o3-2025-04-16": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1e-5,
      "output_cost_per_token": 4e-5,
      "cache_read_input_token_cost": 2.5e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "azure/o4-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1.1e-6,
      "output_cost_per_token": 4.4e-6,
      "cache_read_input_token_cost": 2.75e-7,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000006,
      "input_cost_per_audio_token": 0.00001,
      "cache_read_input_token_cost": 0.0000003,
      "cache_creation_input_audio_token_cost": 0.0000003,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_audio_token": 0.00002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000066,
      "input_cost_per_audio_token": 0.000011,
      "cache_read_input_token_cost": 0.00000033,
      "cache_creation_input_audio_token_cost": 0.00000033,
      "output_cost_per_token": 0.00000264,
      "output_cost_per_audio_token": 0.000022,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000066,
      "input_cost_per_audio_token": 0.000011,
      "cache_read_input_token_cost": 0.00000033,
      "cache_creation_input_audio_token_cost": 0.00000033,
      "output_cost_per_token": 0.00000264,
      "output_cost_per_audio_token": 0.000022,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_audio_token": 0.00004,
      "cache_read_input_token_cost": 0.0000025,
      "output_cost_per_token": 0.00002,
      "output_cost_per_audio_token": 0.00008,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5.5e-6,
      "input_cost_per_audio_token": 44e-6,
      "cache_read_input_token_cost": 2.75e-6,
      "cache_read_input_audio_token_cost": 2.5e-6,
      "output_cost_per_token": 22e-6,
      "output_cost_per_audio_token": 80e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5.5e-6,
      "input_cost_per_audio_token": 44e-6,
      "cache_read_input_token_cost": 2.75e-6,
      "cache_read_input_audio_token_cost": 2.5e-6,
      "output_cost_per_token": 22e-6,
      "output_cost_per_audio_token": 80e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_audio_token": 0.0001,
      "cache_read_input_token_cost": 0.0000025,
      "cache_creation_input_audio_token_cost": 0.00002,
      "output_cost_per_token": 0.00002,
      "output_cost_per_audio_token": 0.0002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_audio_token": 0.00011,
      "cache_read_input_token_cost": 0.00000275,
      "cache_creation_input_audio_token_cost": 0.000022,
      "output_cost_per_token": 0.000022,
      "output_cost_per_audio_token": 0.00022,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_audio_token": 0.00011,
      "cache_read_input_token_cost": 0.00000275,
      "cache_creation_input_audio_token_cost": 0.000022,
      "output_cost_per_token": 0.000022,
      "output_cost_per_audio_token": 0.00022,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/o4-mini-2025-04-16": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 1.1e-6,
      "output_cost_per_token": 4.4e-6,
      "cache_read_input_token_cost": 2.75e-7,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_tool_choice": true
    },
    "azure/o3-mini-2025-01-31": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 0.00000055,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_reasoning": true,
      "supports_vision": false,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/us/o3-mini-2025-01-31": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 0.000000605,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "cache_read_input_token_cost": 0.000000605,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/eu/o3-mini-2025-01-31": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 0.000000605,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "cache_read_input_token_cost": 0.000000605,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/tts-1": {
      "mode": "audio_speech",
      "input_cost_per_character": 0.000015,
      "litellm_provider": "azure"
    },
    "azure/tts-1-hd": {
      "mode": "audio_speech",
      "input_cost_per_character": 0.000030,
      "litellm_provider": "azure"
    },
    "azure/whisper-1": {
      "mode": "audio_transcription",
      "input_cost_per_second": 0.0001,
      "output_cost_per_second": 0.0001,
      "litellm_provider": "azure"
    },
    "azure/o3-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 0.00000055,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "azure/o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "output_cost_per_token": 0.00000484,
      "cache_read_input_token_cost": 0.000000605,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true
    },
    "azure/o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 1.1e-6,
      "output_cost_per_token": 4.4e-6,
      "cache_read_input_token_cost": 0.55e-6,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true
    },
    "azure/us/o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 0.000000605,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "cache_read_input_token_cost": 0.000000605,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_prompt_caching": true
    },
    "azure/eu/o1-mini-2024-09-12": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 0.000000605,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "cache_read_input_token_cost": 0.000000605,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_prompt_caching": true
    },
    "azure/o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/o1-2024-12-17": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/us/o1-2024-12-17": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000165,
      "output_cost_per_token": 0.000066,
      "cache_read_input_token_cost": 0.00000825,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/eu/o1-2024-12-17": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000165,
      "output_cost_per_token": 0.000066,
      "cache_read_input_token_cost": 0.00000825,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/o1-preview": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true
    },
    "azure/o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000060,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_reasoning": true,
      "supports_prompt_caching": true
    },
    "azure/us/o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000165,
      "output_cost_per_token": 0.000066,
      "cache_read_input_token_cost": 0.00000825,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_prompt_caching": true
    },
    "azure/eu/o1-preview-2024-09-12": {
      "max_tokens": 32768,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000165,
      "output_cost_per_token": 0.000066,
      "cache_read_input_token_cost": 0.00000825,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_prompt_caching": true
    },
    "azure/gpt-4.5-preview": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000075,
      "output_cost_per_token": 0.00015,
      "input_cost_per_token_batches": 0.0000375,
      "output_cost_per_token_batches": 0.000075,
      "cache_read_input_token_cost": 0.0000375,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/global/gpt-4o-2024-11-20": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/global/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-11-20": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "output_cost_per_token": 0.000011,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/us/gpt-4o-2024-11-20": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "cache_creation_input_token_cost": 0.00000138,
      "output_cost_per_token": 0.000011,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-2024-11-20": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "cache_creation_input_token_cost": 0.00000138,
      "output_cost_per_token": 0.000011,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-05-13": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.000010,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "deprecation_date": "2025-08-20"
    },
    "azure/us/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "output_cost_per_token": 0.000011,
      "cache_read_input_token_cost": 0.000001375,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-2024-08-06": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "output_cost_per_token": 0.000011,
      "cache_read_input_token_cost": 0.000001375,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.000010,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true,
      "deprecation_date": "2025-12-20"
    },
    "azure/global-standard/gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.00000060,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-2024-07-18": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000083,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000165,
      "output_cost_per_token": 0.00000066,
      "cache_read_input_token_cost": 0.000000083,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-2024-04-09": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-0125-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-1106-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-32k-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure/gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure/gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-vision-preview": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k-0613": {
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-1106": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "deprecation_date": "2025-03-31",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0613": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "deprecation_date": "2025-02-13",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0301": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000002,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "deprecation_date": "2025-02-13",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-0125": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "deprecation_date": "2025-05-31",
      "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-0125": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "deprecation_date": "2025-03-31",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k": {
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure_text",
      "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure_text",
      "mode": "completion"
    },
    "azure/gpt-35-turbo-instruct-0914": {
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure_text",
      "mode": "completion"
    },
    "azure/mistral-large-latest": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/mistral-large-2402": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/command-r-plus": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    "azure/ada": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-ada-002": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-large": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-small": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 0.00000002,
      "output_cost_per_token": 0.000000,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 4.0054321e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/low/1024-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.0490417e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/medium/1024-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 4.0054321e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/high/1024-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.59263611e-7,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/low/1024-x-1536/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.0172526e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/medium/1024-x-1536/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 4.0054321e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/high/1024-x-1536/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.58945719e-7,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/low/1536-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.0172526e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/medium/1536-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 4.0054321e-8,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/high/1536-x-1024/gpt-image-1": {
      "mode": "image_generation",
      "input_cost_per_pixel": 1.58945719e-7,
      "output_cost_per_pixel": 0.0,
      "litellm_provider": "azure",
      "supported_endpoints": [
        "/v1/images/generations"
      ]
    },
    "azure/standard/1024-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.0000000381469,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1024-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000007629,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1024-x-1792/dall-e-3": {
      "input_cost_per_pixel": 0.00000004359,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1792-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000004359,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1024-x-1792/dall-e-3": {
      "input_cost_per_pixel": 0.00000006539,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/hd/1792-x-1024/dall-e-3": {
      "input_cost_per_pixel": 0.00000006539,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure/standard/1024-x-1024/dall-e-2": {
      "input_cost_per_pixel": 0.0,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    "azure_ai/deepseek-r1": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000135,
      "output_cost_per_token": 0.0000054,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367"
    },
    "azure_ai/deepseek-v3": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000114,
      "output_cost_per_token": 0.00000456,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_tool_choice": true,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438"
    },
    "azure_ai/deepseek-v3-0324": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000114,
      "output_cost_per_token": 0.00000456,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438"
    },
    "azure_ai/jamba-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000005,
      "output_cost_per_token": 0.0000007,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure_ai/mistral-nemo": {
      "max_tokens": 4096,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.00000015,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice"
    },
    "azure_ai/mistral-medium-2505": {
      "max_tokens": 8191,
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000004,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    "azure_ai/mistral-large": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure_ai/mistral-small": {
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure_ai/mistral-small-2503": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "azure_ai/mistral-large-2407": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000006,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/mistral-large-latest": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000006,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/ministral-3b": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000004,
      "output_cost_per_token": 0.00000004,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000037,
      "output_cost_per_token": 0.00000037,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "supports_vision": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000071,
      "output_cost_per_token": 0.00000071,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
      "max_tokens": 16384,
      "max_input_tokens": 10000000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000002,
      "output_cost_per_token": 0.00000078,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "supports_vision": true,
      "mode": "chat",
      "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
      "supports_tool_choice": true
    },
    "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "max_tokens": 16384,
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000141,
      "output_cost_per_token": 0.00000035,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "supports_vision": true,
      "mode": "chat",
      "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
      "supports_tool_choice": true
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000204,
      "output_cost_per_token": 0.00000204,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "supports_vision": true,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
      "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.00000037,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.0000003,
      "output_cost_per_token": 0.00000061,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000268,
      "output_cost_per_token": 0.00000354,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
      "max_tokens": 2048,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000533,
      "output_cost_per_token": 0.000016,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-4-mini-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000000075,
      "output_cost_per_token": 0.0000003,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112"
    },
    "azure_ai/Phi-4-multimodal-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000008,
      "input_cost_per_audio_token": 0.000004,
      "output_cost_per_token": 0.00000032,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112"
    },
    "azure_ai/Phi-4": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000000125,
      "output_cost_per_token": 0.0000005,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-mini-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.00000052,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-vision-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.00000052,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": true,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000016,
      "output_cost_per_token": 0.00000064,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.00000052,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000013,
      "output_cost_per_token": 0.00000052,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-small-8k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000006,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-small-128k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000015,
      "output_cost_per_token": 0.0000006,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000017,
      "output_cost_per_token": 0.00000068,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000017,
      "output_cost_per_token": 0.00000068,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_vision": false,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true
    },
    "azure_ai/cohere-rerank-v3-multilingual": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_query_tokens": 2048,
      "input_cost_per_token": 0.0,
      "input_cost_per_query": 0.002,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "rerank"
    },
    "azure_ai/cohere-rerank-v3-english": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_query_tokens": 2048,
      "input_cost_per_token": 0.0,
      "input_cost_per_query": 0.002,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "rerank"
    },
    "azure_ai/Cohere-embed-v3-english": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "output_vector_size": 1024,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "embedding",
      "supports_embedding_image_input": true,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice"
    },
    "azure_ai/Cohere-embed-v3-multilingual": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "output_vector_size": 1024,
      "input_cost_per_token": 0.0000001,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "embedding",
      "supports_embedding_image_input": true,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice"
    },
    "azure_ai/embed-v-4-0": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "output_vector_size": 3072,
      "input_cost_per_token": 0.00000012,
      "output_cost_per_token": 0.0,
      "litellm_provider": "azure_ai",
      "mode": "embedding",
      "supports_embedding_image_input": true,
      "supported_endpoints": [
        "/v1/embeddings"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice"
    }
  }
}
