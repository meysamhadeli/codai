{
  "models": {
    "gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4o": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "input_cost_per_token_batches": 0.00000125,
      "output_cost_per_token_batches": 0.000005,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "output_cost_per_token_batches": 3e-7,
      "cache_read_input_token_cost": 7.5e-8,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 5.5e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true,
      "supports_prompt_caching": true
    },
    "o3-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 5.5e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-3.5-turbo": {
      "max_tokens": 4097,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k": {
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true
    },
    "text-embedding-3-large": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 3072,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 0,
      "input_cost_per_token_batches": 6.5e-8,
      "output_cost_per_token_batches": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "text-embedding-3-small": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "input_cost_per_token_batches": 1e-8,
      "output_cost_per_token_batches": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "text-embedding-ada-002": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    "azure/o3-mini": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "cache_read_input_token_cost": 5.5e-7,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "azure/o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_prompt_caching": true
    },
    "azure/o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "cache_read_input_token_cost": 0.00000125,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4o-mini": {
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "output_cost_per_token": 6.6e-7,
      "cache_read_input_token_cost": 7.5e-8,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-32k": {
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure/gpt-4": {
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-4-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo-16k": {
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "azure/gpt-35-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/gpt-3.5-turbo": {
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "azure/text-embedding-ada-002": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-large": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure/text-embedding-3-small": {
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    "azure_ai/deepseek-r1": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_token_cache_hit": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "claude-3-opus-20240229": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-03-01",
      "supports_tool_choice": true
    },
    "claude-3-5-haiku-20241022": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "tool_use_system_prompt_tokens": 264,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-10-01",
      "supports_tool_choice": true
    },
    "claude-3-5-sonnet-20240620": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-06-01",
      "supports_tool_choice": true
    },
    "claude-3-5-sonnet-20241022": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "deprecation_date": "2025-10-01",
      "supports_tool_choice": true
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-r1": {
      "max_tokens": 8192,
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_token_cache_hit": 1.4e-7,
      "output_cost_per_token": 0.00000219,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true
    },
    "openrouter/deepseek/deepseek-chat": {
      "max_tokens": 8192,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "openrouter",
      "supports_prompt_caching": true,
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/deepseek/deepseek-coder": {
      "max_tokens": 8192,
      "max_input_tokens": 66000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "openrouter",
      "supports_prompt_caching": true,
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku": {
      "max_tokens": 200000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "max_tokens": 8192,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    "openrouter/mistralai/mistral-large": {
      "max_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/o1": {
      "max_tokens": 100000,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "cache_read_input_token_cost": 0.0000075,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/o1-mini": {
      "max_tokens": 65536,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4o": {
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "max_tokens": 4095,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "max_tokens": 16383,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4": {
      "max_tokens": 8192,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_tool_choice": true
    }
  }
}
